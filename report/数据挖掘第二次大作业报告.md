## 数据挖掘第二次大作业报告

组长：罗弈桢

组员：侯振宇 许若虞

### 数据分析与预处理

### 聚类分析与评估

由于数据规模较大，且其中同时存在numerical和nominal的特征，因此采用能够同时处理两类数据的划分方法K-Prototypes和基于密度的方法DBSCAN进行聚类。在评价指标上，除了算法的稳定性和时间复杂度外，选择如下两个指标衡量聚类质量：

- 紧凑度compatness，设k个中心点为$c_1,c_2,\cdots,c_k$，每个点到类簇的平均距离$d_i=\frac{1}{|C_i|}\sum_{j\in C_i}dist(x_j,c_i)$，则紧凑度为簇内平均距离的平均：$C=\frac{1}{k}\sum_{i=1}^kd_i$；
- 分离度speration，即每个簇中心的平均距离：$S=\frac{2}{k^2-k}\sum_{i=1}^k\sum_{j=i+1}^kdist(c_i,c_j)$；

#### K-Prototypes方法
该方法与K-Means类似，但在距离度量和中心点更新的策略上略有不同。对于numerical特征，采用欧几里得距离的平方$(x_{ik}-x_{jk})^2$进行衡量；对于nominal特征，使用$\delta_{ij}=\begin{cases}0,x_{ik}=x_{jk}\\1,x_{ik}\neq x_{jk}\end{cases}$进行衡量（等价于one-hot编码的欧几里得距离），最终的距离是所有特征的距离之和。在中心点更新时，对于numerical特征，使用类簇内所有点的均值进行表示；对于nominal特征，则使用类簇内所有点的众数进行表示。

该算法的优势在于时间复杂度较低，为$O(tnkd)$，其中n为样本数量，k为簇数量，d为特征数量，t为迭代次数，一般t取20~50算法即收敛。从稳定性进行评估，该算法的聚类质量很大程度上依赖于初始中心点的选取，且容易受到outlier的影响。

#### DBSCAN方法

### 实验结果

#### 可视化与可解释性分析

#### 再入院信息分析

